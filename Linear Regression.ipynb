{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network - Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be creating a Neural Network that takes two features as input and produes two features as output. Inbetween the input and output layers are the two hidden layers. We will consider that we have 1000 data in our dataset. `train` is the input dataset which is fed into the network and `train_label` is the output dataset which is used to calculate cost and accuracy of the model.\n",
    "\n",
    "The network will always produes `0.5` as ouput. Its not a very helpful function but it lets us learn alot about the different types of activation functions and their uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plot\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "tf.logging.set_verbosity(tf.logging.WARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=4\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=np.random.rand(1000,2)\n",
    "train_label=np.ones((1000,2))/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use 990 of the available dataset for training the network and the remaining 10 for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=train[-10:,:]\n",
    "y_test=train_label[-10:,:]\n",
    "x_train=train[:-10,:]\n",
    "y_train=train_label[:-10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.placeholder(tf.float32)\n",
    "y=tf.placeholder(tf.float32)\n",
    "\n",
    "\n",
    "input_units=2\n",
    "hidden_units=4\n",
    "output_units=2\n",
    "\n",
    "epoches=5\n",
    "batch_size=1\n",
    "learning_rate=0.01\n",
    "\n",
    "w={\n",
    "    'input':tf.Variable(tf.random_normal([input_units,hidden_units], seed=seed)),\n",
    "    'hidden':tf.Variable(tf.random_normal([hidden_units,hidden_units], seed=seed)),\n",
    "    'output':tf.Variable(tf.random_normal([hidden_units,output_units], seed=seed))\n",
    "}\n",
    "\n",
    "b={\n",
    "    'input':tf.Variable(tf.random_normal([hidden_units],seed=seed)),\n",
    "    'hidden':tf.Variable(tf.random_normal([hidden_units],seed=seed)),\n",
    "    'output':tf.Variable(tf.random_normal([output_units],seed=seed))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets first discuss `sigmoid` and `relu` activation function learn why, where and when we should use them.\n",
    "The most easy and commonly used is the `Sigmoid/Logistic` activation function.\n",
    "\n",
    "##### sigmoid(x)\n",
    "- It has an output range of (0,1) i.e it maps (-$\\infty$,$\\infty$) to (0,1).\n",
    "- As $x\\to \\infty$ or $x\\to -\\infty$ its affect on the ouput decreases exponentially. \n",
    "- Gradient of function is very small for large value of `x`.\n",
    "- It suffers from `vanishing gradient` problem (the futher the gradient is passed, the smaller it gets. Thus at one point it becomes so small that it has to effect in the calculation of the error which leads to untrained networks.).\n",
    "\n",
    "##### Why?\n",
    "- Its very easy to understand.\n",
    "- Has nomalizing property.\n",
    "- Gradient is easy to calculate.\n",
    "\n",
    "##### Where?\n",
    "- Due to its normalizing property it is used in the output layer of the neural network.\n",
    "- Can be used in the hidden layers of shallow networks.\n",
    "\n",
    "##### When?\n",
    "- Should be in output layer when output of the neural network is expected to be in range of (0,1) which can then be scaled to requried magnitude. Functions similar to sigmoid can be used in the output layer as according to the required output range.\n",
    "\n",
    "\n",
    "Function with similar characteristics are $tan^{-1}(x)$ and $tanh(x)$ and have their own advantages over the other.\n",
    "\n",
    "To solve the vanishing gradient problem `Rectified Linear Unit` or `ReLU` in short\n",
    "\n",
    "##### relu(x)\n",
    "- It has an output range of \\[0,$\\infty$) i.e it maps (-$\\infty$,$\\infty$) to \\[0,$\\infty$).\n",
    "- It solves the vanishing gradient problem by replacing the curve with a straight line.\n",
    "- It suffers from `dying Relu` problem where a negetive values are mapped to 0 causing the node to become inactive and thus no learning takes place which is solved in `Leaky ReLU` and other similar functions.\n",
    "\n",
    "##### Why?\n",
    "- Significantly increases efficieny due to the linearity of the function.\n",
    "- It addresses the vanishing gradient problem.\n",
    "\n",
    "##### Where?\n",
    "- As it rectifies the vanishing gradient problem it is used in the hidden layers of the deep neural network.\n",
    "- Can be used in the output layer when creating a classifier.\n",
    "\n",
    "##### When?\n",
    "- When ever creating deep networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computational Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are creating a regression neural network the use of normalizing activation function (such as `sigmoid`, `arcTan` or `tanh`) at the output layer is __very__ important. It makes sure that all of the calculated values are normalized to `(0,1)`, `(-1,1)`... depending on the function used. If `relu` was used, it would perform `x>0?x:0` and since `x` is returned, it need to be normalized externally. `relu` however can be used internally as cost minimization is used to tune the weights accordingly ,i.e whatever the nodes may output, the neural network learns and adjusts its weights to obtain required output.\n",
    "\n",
    "This is however not required during classification as the __maximum node's index__ is picked which is always a constant and never calculated. Eg, during hand written digit classification, we have 10 output nodes and the node with the greatest value is picked and its index position is returned. It does not matter if the value at the nodes were `-100`, `-0.01` or `81234`. We pick the maximum value and thus always end up with the results as expected. Where as in regression, we always expect a normalized value which is then projected to a required value later.\n",
    "\n",
    "But why use `relu` at all? why not use `sigmoid` or simialr function all the way?\n",
    "The problem with this type of function lies in its shape. As the value of `x` becomes very large or small, its affect on the ouput of the function deminishes and with that the gradient of the function. Thus, in a deep network when propagating the gradient backwards, it sometimes becomes so small that is does not propagate any further than a few layers. Thus, `relu` was created to solve this problem i.e `vanishing gradient problem`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_1=tf.matmul(x,w['input'])+b['input']\n",
    "hidden_layer_1=tf.nn.relu(hidden_layer_1)\n",
    "\n",
    "hidden_layer_2=tf.matmul(hidden_layer_1,w['hidden'])+b['hidden']\n",
    "hidden_layer_2=tf.nn.relu(hidden_layer_2)\n",
    "\n",
    "output_layer=tf.matmul(hidden_layer_2,w['output'])+b['output']\n",
    "output_layer=tf.nn.sigmoid(output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using `Cross entropy` loss function to calculate the cost/loss. `AdamOptimizer` is used to minimize the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=output_layer,labels=y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "init=tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch(index):\n",
    "    s=index*batch_size\n",
    "    e=s+batch_size\n",
    "    x_batch=x_train[s:e,:]\n",
    "    y_batch=y_train[s:e]\n",
    "    return x_batch,y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ses=tf.Session()\n",
    "ses.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1  average cost:  0.693162857402\n",
      "epoch:  2  average cost:  0.6931476764\n",
      "epoch:  3  average cost:  0.693147185114\n",
      "epoch:  4  average cost:  0.693147242069\n",
      "epoch:  5  average cost:  0.693147569293\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c436128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_batch=int(x_train.shape[0]/batch_size)\n",
    "e=[]\n",
    "for epoch in range(epoches):\n",
    "    avg_cost=0\n",
    "    for i in range(total_batch):\n",
    "        batch_x,batch_y=create_batch(i)\n",
    "        o,c=ses.run([optimizer,cost],feed_dict={x:batch_x,y:batch_y})\n",
    "        avg_cost+=c/total_batch\n",
    "    e.append(avg_cost)\n",
    "    print(\"epoch: \",epoch+1,\" average cost: \",avg_cost)\n",
    "plot.plot(e)\n",
    "plot.xlabel(\"number of epoch\")\n",
    "plot.ylabel(\"average loss\")\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_0</th>\n",
       "      <th>p_1</th>\n",
       "      <th>x_0</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_0</th>\n",
       "      <th>y_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.554942</td>\n",
       "      <td>0.554977</td>\n",
       "      <td>0.158722</td>\n",
       "      <td>0.612056</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.562598</td>\n",
       "      <td>0.562574</td>\n",
       "      <td>0.447591</td>\n",
       "      <td>0.845948</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.551668</td>\n",
       "      <td>0.551731</td>\n",
       "      <td>0.415480</td>\n",
       "      <td>0.448498</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.561957</td>\n",
       "      <td>0.561936</td>\n",
       "      <td>0.136925</td>\n",
       "      <td>0.874424</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.562999</td>\n",
       "      <td>0.562974</td>\n",
       "      <td>0.738024</td>\n",
       "      <td>0.812036</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.552815</td>\n",
       "      <td>0.552871</td>\n",
       "      <td>0.599244</td>\n",
       "      <td>0.459854</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.552157</td>\n",
       "      <td>0.552219</td>\n",
       "      <td>0.729622</td>\n",
       "      <td>0.413760</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.544106</td>\n",
       "      <td>0.544230</td>\n",
       "      <td>0.634510</td>\n",
       "      <td>0.088047</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.564889</td>\n",
       "      <td>0.564844</td>\n",
       "      <td>0.111721</td>\n",
       "      <td>0.987038</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.553003</td>\n",
       "      <td>0.553058</td>\n",
       "      <td>0.651013</td>\n",
       "      <td>0.458083</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         p_0       p_1       x_0       x_1  y_0  y_1\n",
       "1   0.554942  0.554977  0.158722  0.612056  0.5  0.5\n",
       "2   0.562598  0.562574  0.447591  0.845948  0.5  0.5\n",
       "3   0.551668  0.551731  0.415480  0.448498  0.5  0.5\n",
       "4   0.561957  0.561936  0.136925  0.874424  0.5  0.5\n",
       "5   0.562999  0.562974  0.738024  0.812036  0.5  0.5\n",
       "6   0.552815  0.552871  0.599244  0.459854  0.5  0.5\n",
       "7   0.552157  0.552219  0.729622  0.413760  0.5  0.5\n",
       "8   0.544106  0.544230  0.634510  0.088047  0.5  0.5\n",
       "9   0.564889  0.564844  0.111721  0.987038  0.5  0.5\n",
       "10  0.553003  0.553058  0.651013  0.458083  0.5  0.5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction=ses.run(output_layer,{x:x_test})\n",
    "data={'x_0':x_test[:,0],'x_1':x_test[:,1],\n",
    "      'y_0':y_test[:,0],'y_1':y_test[:,1],\n",
    "      'p_0':prediction[:,0],'p_1':prediction[:,1]}\n",
    "df=pd.DataFrame(data=data)\n",
    "df.index+=1\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.99681\n"
     ]
    }
   ],
   "source": [
    "score=1-tf.reduce_mean(tf.squared_difference(prediction,y_test))\n",
    "print(\"accuracy:\",ses.run(score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
